{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fa5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from periomod.data import ProcessedDataLoader\n",
    "from periomod.resampling import Resampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataloader = ProcessedDataLoader(\n",
    "    task=\"pocketclosure\",\n",
    "    encoding=\"onehot\",\n",
    "    encode=False, \n",
    "    scale=False\n",
    ")\n",
    "\n",
    "data = dataloader.load_data(path=\"../data/processed/processed_data.csv\")\n",
    "resampler = Resampler(classification=\"binary\", encoding=\"one_hot\")\n",
    "train_df, test_df = resampler.split_train_test_df(df=data)\n",
    "\n",
    "val_df = dataloader.load_data(path=\"../data/processed/Leuven_Dataset_v2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bfd5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "1    53028\n",
       "0    46896\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec0f921",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/series.py:248\u001b[0m, in \u001b[0;36m_coerce_method.<locals>.wrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert the series to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <class 'float'>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/series.py:1298\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_with_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;66;03m# We have a scalar (or for MultiIndex or object-dtype, scalar-like)\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;66;03m#  key that is not present in self.index.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/series.py:1373\u001b[0m, in \u001b[0;36mSeries._set_with_engine\u001b[0;34m(self, key, value, warn)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;66;03m# this is equivalent to self._values[key] = value\u001b[39;00m\n\u001b[0;32m-> 1373\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/internals/managers.py:2044\u001b[0m, in \u001b[0;36mSingleBlockManager.setitem_inplace\u001b[0;34m(self, indexer, value, warn)\u001b[0m\n\u001b[1;32m   2038\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2039\u001b[0m             COW_WARNING_SETITEM_MSG,\n\u001b[1;32m   2040\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   2041\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   2042\u001b[0m         )\n\u001b[0;32m-> 2044\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/internals/base.py:363\u001b[0m, in \u001b[0;36mSingleDataManager.setitem_inplace\u001b[0;34m(self, indexer, value, warn)\u001b[0m\n\u001b[1;32m    361\u001b[0m     value \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m--> 363\u001b[0m \u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1429\u001b[0m, in \u001b[0;36mBlock.setitem\u001b[0;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1429\u001b[0m     \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m casted\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m stageimputer\u001b[38;5;241m=\u001b[39m_helpers\u001b[38;5;241m.\u001b[39mPeriodontalStageGradeExtentCalculator()\n\u001b[0;32m----> 6\u001b[0m data\u001b[38;5;241m=\u001b[39m \u001b[43mstageimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_stage_grade_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pa-modeling/periomod/data/_helpers.py:817\u001b[0m, in \u001b[0;36mPeriodontalStageGradeExtentCalculator.assign_stage_grade_extent\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    815\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_stage_per_patient(df)\n\u001b[1;32m    816\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_grade_per_site(df)\n\u001b[0;32m--> 817\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_grade_per_patient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/pa-modeling/periomod/data/_helpers.py:760\u001b[0m, in \u001b[0;36mPeriodontalStageGradeExtentCalculator._calculate_grade_per_patient\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03mAssigns the highest periodontal grade per patient.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;124;03m    pd.DataFrame: DataFrame with a new 'grade' column assigned per patient.\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    759\u001b[0m grade_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mside\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m6\u001b[39m])]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 760\u001b[0m grade_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade_temp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrade_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_grade_per_site\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m max_grade_per_patient \u001b[38;5;241m=\u001b[39m grade_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_patient\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade_temp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m    763\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/pa-modeling/periomod/data/_helpers.py:745\u001b[0m, in \u001b[0;36mPeriodontalStageGradeExtentCalculator._calculate_grade_per_site\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    742\u001b[0m grade[(bl_age \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (grade \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (smoke \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m&\u001b[39m (diabetes \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    743\u001b[0m grade[(bl_age \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.25\u001b[39m) \u001b[38;5;241m&\u001b[39m ((smoke \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m (diabetes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 745\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrade\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m grade\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/series.py:1327\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# The key was OK, but we cannot set the value losslessly\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m-> 1327\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidIndexError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   1331\u001b[0m         \u001b[38;5;66;03m# cases with MultiIndex don't get here bc they raise KeyError\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m         \u001b[38;5;66;03m# e.g. test_basic_getitem_setitem_corner\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/series.py:1419\u001b[0m, in \u001b[0;36mSeries._set_values\u001b[0;34m(self, key, value, warn)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Index, Series)):\n\u001b[1;32m   1417\u001b[0m     key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_update_cacher()\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/internals/managers.py:415\u001b[0m, in \u001b[0;36mBaseBlockManager.setitem\u001b[0;34m(self, indexer, value, warn)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# No need to split if we either set all columns or on a single block\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# manager\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetitem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/pamod/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1432\u001b[0m, in \u001b[0;36mBlock.setitem\u001b[0;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1431\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_list_like(casted):\n\u001b[0;32m-> 1432\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1433\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetting an array element with a sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1434\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from periomod.data import ProcessedDataLoader, _helpers\n",
    "from periomod.resampling import Resampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "stageimputer=_helpers.PeriodontalStageGradeExtentCalculator()\n",
    "data= stageimputer.assign_stage_grade_extent(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea7d4a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extent\n",
       "0    63168\n",
       "1    36756\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"extent\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ec8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _get_occluding_teeth():\n",
    "    \"\"\"\n",
    "    Load the occluding teeth mapping from the specified CSV file.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping tooth numbers to their occluding teeth.\n",
    "    \"\"\"\n",
    "    occluding_pairs = [(17, 47), (16, 46), (15, 45), (14, 44), (13, 43),\n",
    "            (12, 42), (11, 41), (21, 31), (22, 32), (23, 33), (24, 34), \n",
    "            (25, 35), (26, 36), (27, 37)]\n",
    "\n",
    "    return occluding_pairs\n",
    "\n",
    "def _calculate_occluding_pairs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of occluding pairs of teeth per patient \n",
    "    and assign to a new column \"occluding_pairs\" per row.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing patient data with \n",
    "            columns \"id_patient\" and \"tooth\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column \"occluding_pairs\" \n",
    "            indicating the number of occluding pairs per patient.\n",
    "    \"\"\"\n",
    "    occluding_pairs = _get_occluding_teeth()\n",
    "    df_teeth = df.groupby([\"id_patient\", \"tooth\"]).size().reset_index()[[\"id_patient\", \"tooth\"]]\n",
    "    \n",
    "    # Build a mapping of patient_id -> set of teeth\n",
    "    patient_teeth = df_teeth.groupby(\"id_patient\")[\"tooth\"].apply(set)\n",
    "\n",
    "    # Count occluding pairs per patient\n",
    "    occlusion_map = {\n",
    "        patient_id: sum(1 for upper, lower in occluding_pairs if upper in teeth and lower in teeth)\n",
    "        for patient_id, teeth in patient_teeth.items()\n",
    "    }\n",
    "\n",
    "    # Map occluding pair counts back to original DataFrame\n",
    "    df[\"occluding_pairs\"] = df[\"id_patient\"].map(occlusion_map)\n",
    "    return df\n",
    "\n",
    "def _calculate_stage_for_row_occludingpairs(row: pd.Series) -> int:\n",
    "    \"\"\"Calculates the periodontal stage for a given row based \n",
    "    on CAL and missing teeth.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing 'CAL' and\n",
    "            'missing_teeth' columns.\n",
    "\n",
    "    Returns:\n",
    "        int: The periodontal stage:\n",
    "            - 4 if CAL >= 5 and missing teeth >= 5\n",
    "            - 3 if CAL >= 5 and missing teeth < 5\n",
    "            - 2 if CAL in [3, 4]\n",
    "            - 1 if CAL in [1, 2]\n",
    "            - 0 otherwise\n",
    "    \"\"\"\n",
    "    cal = row['CAL']\n",
    "    missing = row.get('missing_teeth', 0)\n",
    "    occluding_pairs= row.get('occluding_pairs', 0)\n",
    "    furcation_involvement = row.get(\"furcationbaseline\", 0)\n",
    "\n",
    "    if cal >= 5 and occluding_pairs < 10:\n",
    "        return 4\n",
    "    elif cal >= 5 and occluding_pairs > 9:\n",
    "        return 3\n",
    "    elif cal in [3, 4]:\n",
    "        if furcation_involvement > 1:\n",
    "            return 3\n",
    "        else:\n",
    "            return 2\n",
    "    elif cal in [1, 2]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def _calculate_cal(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the CAL (Clinical Attachment Level) for each row in the DataFrame.\n",
    "    The formula used is: CAL = PDBaseline + RecBaseline - 3\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing patient data with columns \n",
    "        \"pdbaseline\" and \"recbaseline\".\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column \"CAL\" indicating \n",
    "        the Clinical Attachment Level.\n",
    "    \"\"\"\n",
    "    data[\"CAL\"] = np.where(\n",
    "        data[\"recbaseline\"] > 0,\n",
    "        data[\"pdbaseline\"] + data[\"recbaseline\"],\n",
    "        data[\"pdbaseline\"] - 3\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def _calculate_missing_teeth_per_patient(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of missing teeth per patient (excluding wisdom teeth)\n",
    "    and assign to a new column \"missing_teeth\" per row.\n",
    "\n",
    "    Args:  \n",
    "        data (pd.DataFrame): DataFrame containing patient data with columns \"id_patient\" and \"tooth\".\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column \"missing_teeth\" indicating the number of missing teeth per patient.\n",
    "    \"\"\"\n",
    "    fdi_teeth = [t for t in range(11, 49) if t % 10 not in [0, 8, 9]]\n",
    "\n",
    "    missing_teeth_dict = {}\n",
    "\n",
    "    for id in data[\"id_patient\"].unique():\n",
    "        patient_teeth = data[(data[\"id_patient\"] == id)][\"tooth\"]\n",
    "        patient_teeth = patient_teeth[~patient_teeth.isin([18, 28, 38, 48])].unique()\n",
    "\n",
    "        missing_teeth = len(set(fdi_teeth) - set(patient_teeth))\n",
    "        missing_teeth_dict[id] = missing_teeth\n",
    "\n",
    "    data[\"missing_teeth\"] = data[\"id_patient\"].map(missing_teeth_dict)\n",
    "\n",
    "    return data\n",
    "\n",
    "def _calculate_stage_by_patient(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assigns:\n",
    "    - 'tooth_stage': stage per row (site) based on CAL and occluding pairs\n",
    "    - 'max_stage': maximum stage per patient, with upgrade if ≥2 non-adjacent teeth have PPD ≥ 6 mm\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with \"id_patient\", \"side\", \"CAL\", \"pdbaseline\", \"tooth\", and \"occluding_pairs\"\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with added columns:\n",
    "            - 'tooth_stage': row-specific stage\n",
    "            - 'max_stage': highest stage found for the patient (after rule)\n",
    "    \"\"\"\n",
    "    # Apply tooth-level staging\n",
    "    stage_df = df[df[\"side\"].isin([1, 3, 4, 6])].copy()\n",
    "    stage_df['tooth_stage'] = stage_df.apply(_calculate_stage_for_row_occludingpairs, axis=1)\n",
    "\n",
    "    # Initialize patient stage mapping\n",
    "    stage_map = {}\n",
    "\n",
    "    # Tooth adjacency map (FDI, excluding third molars)\n",
    "    adjacent_pairs = {\n",
    "        11: [12, 21], 12: [11, 13], 13: [12, 14], 14: [13, 15], 15: [14, 16], 16: [15, 17], 17: [16],\n",
    "        21: [11, 22], 22: [21, 23], 23: [22, 24], 24: [23, 25], 25: [24, 26], 26: [25, 27], 27: [26],\n",
    "        31: [32, 41], 32: [31, 33], 33: [32, 34], 34: [33, 35], 35: [34, 36], 36: [35, 37], 37: [36],\n",
    "        41: [31, 42], 42: [41, 43], 43: [42, 44], 44: [43, 45], 45: [44, 46], 46: [45, 47], 47: [46]\n",
    "    }\n",
    "\n",
    "    for patient_id, group in stage_df.groupby(\"id_patient\"):\n",
    "        max_stage = group[\"tooth_stage\"].max()\n",
    "\n",
    "        # Check if upgrade condition applies (PPD ≥ 6 at ≥2 non-adjacent teeth)\n",
    "        if max_stage == 2:\n",
    "            ppd_teeth = set(group[group[\"pdbaseline\"] >= 6][\"tooth\"].unique())\n",
    "            non_adjacent_teeth = []\n",
    "\n",
    "            for tooth in ppd_teeth:\n",
    "                if all(tooth not in adjacent_pairs.get(other, []) for other in ppd_teeth if other != tooth):\n",
    "                    non_adjacent_teeth.append(tooth)\n",
    "\n",
    "            if len(non_adjacent_teeth) >= 2:\n",
    "                max_stage = 3  # Upgrade due to non-adjacent deep pockets\n",
    "\n",
    "        stage_map[patient_id] = max_stage\n",
    "\n",
    "    # Map results back to full dataframe\n",
    "    df['tooth_stage'] = df.apply(_calculate_stage_for_row_occludingpairs, axis=1)\n",
    "    df['max_stage'] = df['id_patient'].map(stage_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "def impute_stage(self, df):\n",
    "    \"\"\"\n",
    "    Assign the highest periodontal stage per patient based on CAL and missing teeth.\n",
    "    Returns a DataFrame with the 'stage' column added.\n",
    "    \"\"\"\n",
    "    df = _calculate_occluding_pairs(df)\n",
    "    df = _calculate_missing_teeth_per_patient(df)\n",
    "    df = _calculate_cal(df)\n",
    "    df = _calculate_stage_by_patient(df)\n",
    "    return df\n",
    "\n",
    "def _get_sideencoding():\n",
    "    \"\"\"\n",
    "    Load the side encoding mapping for tooth surfaces.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping surface labels to their corresponding site indices.\n",
    "    \"\"\"\n",
    "    sideencoding = {\"m\": [3, 4], \"d\": [1, 6], \"b\": [2], \"o\": [5]}\n",
    "    return sideencoding\n",
    "\n",
    "def _get_gender_map():\n",
    "    \"\"\"\n",
    "    Load the gender mapping for patient data.\n",
    "    Returns:\n",
    "        dict: A dictionary\n",
    "    \"\"\"\n",
    "    gender_map = {0: \"women\", 1: \"men\"}\n",
    "    return gender_map\n",
    "\n",
    "def _get_surface_label(site_index: int):\n",
    "    \"\"\"\n",
    "    Get the surface label based on the site index.\n",
    "    Args:\n",
    "        site_index (int): The index of the site (1-6).\n",
    "    \n",
    "    Returns:\n",
    "        str: The surface label (\"m\", \"d\", \"avg_md\", or None\n",
    "    \"\"\"\n",
    "    sideencoding = _get_sideencoding()\n",
    "    if site_index in sideencoding[\"m\"]:\n",
    "        return \"m\"\n",
    "    elif site_index in sideencoding[\"d\"]:\n",
    "        return \"d\"\n",
    "    elif site_index in sideencoding[\"b\"] or site_index in sideencoding[\"o\"]:\n",
    "        return \"avg_md\"\n",
    "    return None\n",
    "\n",
    "def _get_rootlength_data():\n",
    "    \"\"\"\n",
    "    Load root length data from the specified CSV file.\n",
    "    \"\"\"\n",
    "    rootlength = pd.read_csv(\"Revision/root_length_percentages.csv\")\n",
    "    return rootlength\n",
    "\n",
    "def _calculate_bone_loss_percentage_row(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the bone loss percentage for a given row.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing 'pdbaseline', 'recbaseline', 'tooth', 'side', and\n",
    "\n",
    "    Returns:\n",
    "        float: The bone loss percentage calculated using the formula:\n",
    "               Bone Loss Percentage = (PDBaseline + RecBaseline) / Root Length * 100\n",
    "               Returns None if the root length is not found.\n",
    "    \"\"\"\n",
    "    rootlengthmap = _get_rootlength_data()\n",
    "    gender_map = _get_gender_map()\n",
    "    tooth = row['tooth']\n",
    "    surface = _get_surface_label(row['side'])\n",
    "    gender = gender_map[row['gender']]\n",
    "\n",
    "    if surface == \"avg_md\":\n",
    "        m = rootlengthmap[\n",
    "            (rootlengthmap['Tooth'] == tooth) &\n",
    "            (rootlengthmap['Gender'] == gender) &\n",
    "            (rootlengthmap['Surface'] == 'm')\n",
    "        ]['R'].values\n",
    "        d = rootlengthmap[\n",
    "            (rootlengthmap['Tooth'] == tooth) &\n",
    "            (rootlengthmap['Gender'] == gender) &\n",
    "            (rootlengthmap['Surface'] == 'd')\n",
    "        ]['R'].values\n",
    "        if len(m) == 0 or len(d) == 0:\n",
    "            return None\n",
    "        root_length = (m[0] + d[0]) / 2\n",
    "    else:\n",
    "        r = rootlengthmap[\n",
    "            (rootlengthmap['Tooth'] == tooth) &\n",
    "            (rootlengthmap['Gender'] == gender) &\n",
    "            (rootlengthmap['Surface'] == surface)\n",
    "        ]['R'].values\n",
    "        if len(r) == 0:\n",
    "            return None\n",
    "        root_length = r[0]\n",
    "    return round((row['pdbaseline'] + row['recbaseline']-3) / root_length, 1)* 100\n",
    "\n",
    "def _apply_bone_loss_percentage(df: pd.DataFrame\n",
    "                                   ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the bone loss percentage for each row in the DataFrame.\n",
    "    The formula used is: Bone Loss Percentage = (PDBaseline + RecBaseline) / Root Length * 100\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing patient data with columns \"pdbaseline\", \"recbaseline\", \"tooth\", \"side\", and\n",
    "    \n",
    "    returns:\n",
    "        pd.DataFrame: DataFrame with an additional column \"bone_loss_percentage\" indicating the bone loss percentage.\n",
    "    \"\"\"\n",
    "    df['bone_loss_percentage'] = df.apply(_calculate_bone_loss_percentage_row, axis=1)\n",
    "    return df\n",
    "\n",
    "def _calculate_boneloss_per_age(df: pd.DataFrame\n",
    "                               )-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the bone loss per age for each row in the DataFrame.\n",
    "    The formula used is: Bone Loss per Age = Bone Loss Percentage / Age\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing patient data with columns \"bone_loss_percentage\" and \"age\".\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column \"bl/age\" indicating the bone loss per age.\n",
    "    \"\"\"\n",
    "    df[\"bl/age\"] = df[\"bone_loss_percentage\"] / df[\"age\"]\n",
    "    return df\n",
    "\n",
    "def _grade_from_row(row: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Determine the periodontal grade based on bone loss percentage and age.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing 'bl/age'.\n",
    "    \n",
    "    Returns:\n",
    "        int: The periodontal grade (0, 1, or 2).\n",
    "    \"\"\"\n",
    "    bl_age = row['bl/age']\n",
    "    cigarettenumber = row.get(\"cigarettenumber\", 0)\n",
    "    diabetes = row.get(\"diabetes\", 0)\n",
    "\n",
    "    if bl_age < 0.25:\n",
    "        if cigarettenumber >= 10:\n",
    "            return 2\n",
    "        if cigarettenumber > 0 or diabetes > 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif bl_age < 1:\n",
    "        if cigarettenumber >= 10:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def _assign_grade(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign the periodontal grade based on the bone loss percentage and age.\n",
    "    Returns a DataFrame with the 'grade' column added.\n",
    "    \"\"\"\n",
    "    df['grade'] = df.apply(_grade_from_row, axis=1)\n",
    "    return df\n",
    "\n",
    "def _calculate_grade_by_patient(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign the highest periodontal grade per patient based on the number of missing teeth.\n",
    "    Returns a DataFrame with the 'grade' column added.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing patient data with columns \"id_patient\", \"side\", \"bl/age\".\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column \"grade\" indicating the highest periodontal grade per patient.\n",
    "    \"\"\"\n",
    "    grade_df = df[df[\"side\"].isin([1, 3, 4, 6])].copy()\n",
    "    grade_df['grade_temp'] = grade_df.apply(_grade_from_row, axis=1)\n",
    "    max_grade_per_patient = grade_df.groupby('id_patient')['grade_temp'].max()\n",
    "    df['grade'] = df['id_patient'].map(max_grade_per_patient)\n",
    "\n",
    "    return df\n",
    "\n",
    "def assign_grade_by_patient(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign the highest periodontal grade per patient based on the bone loss percentage and age.\n",
    "    Returns a DataFrame with the 'grade' column added.\n",
    "    \"\"\"\n",
    "    df = _apply_bone_loss_percentage(df)\n",
    "    df = _calculate_boneloss_per_age(df)\n",
    "    df = _assign_grade(df)\n",
    "    df = _calculate_grade_by_patient(df)\n",
    "    return df\n",
    "\n",
    "def assign_extent(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the extent of periodontal disease for each patient based on the maximum stage\n",
    "    and the percentage of teeth at that stage.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing patient data with columns \"id_patient\", \"side\", \"tooth_stage\", \"missing_teeth\".\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with additional columns \"extent\" and \"percent_max_stage\".\n",
    "    \"\"\"\n",
    "    extent_map = {}\n",
    "    percent_map = {}\n",
    "    df_side = df[df[\"side\"].isin([1, 3, 4, 6])].copy()\n",
    "\n",
    "    for patient_id in df_side[\"id_patient\"].unique():\n",
    "        patient_data = df_side[df_side[\"id_patient\"] == patient_id]\n",
    "        patient_tooth_data = patient_data.groupby(\"tooth\").max(numeric_only=True)\n",
    "\n",
    "        max_stage = patient_tooth_data[\"max_stage\"].max()\n",
    "        max_stage_count = (patient_tooth_data[\"tooth_stage\"] == max_stage).sum()\n",
    "        total_teeth = patient_tooth_data.shape[0]\n",
    "\n",
    "        percent_max_stage = (max_stage_count / total_teeth * 100) if total_teeth > 0 else 0\n",
    "        extent = int(percent_max_stage >= 30)\n",
    "\n",
    "        extent_map[patient_id] = extent\n",
    "        percent_map[patient_id] = percent_max_stage\n",
    "\n",
    "    df[\"extent\"] = df[\"id_patient\"].map(extent_map)\n",
    "    df[\"percent_max_stage\"] = df[\"id_patient\"].map(percent_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _get_summary_data(\n",
    "    train: pd.DataFrame, \n",
    "    test: pd.DataFrame, \n",
    "    val: pd.DataFrame, \n",
    "    predictor: list = [\"max_stage\", \"grade\", \"extent\"]\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize predictor counts and percentages across train, test, and validation sets.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns:\n",
    "        ['predictor', 'category', 'train', 'test', 'val', 'train_percent', 'test_percent', 'val_percent']\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for pred in predictor:\n",
    "        # Aggregate per patient\n",
    "        train_counts = train.groupby(\"id_patient\")[pred].first().value_counts().sort_index()\n",
    "        test_counts  = test.groupby(\"id_patient\")[pred].first().value_counts().sort_index()\n",
    "        val_counts   = val.groupby(\"id_patient\")[pred].first().value_counts().sort_index()\n",
    "\n",
    "        all_categories = sorted(set(train_counts.index) | set(test_counts.index) | set(val_counts.index))\n",
    "\n",
    "        for cat in all_categories:\n",
    "            train_n = train_counts.get(cat, 0)\n",
    "            test_n  = test_counts.get(cat, 0)\n",
    "            val_n   = val_counts.get(cat, 0)\n",
    "\n",
    "            train_pct = round(train_n / train_counts.sum() * 100, 1) if train_counts.sum() else 0\n",
    "            test_pct  = round(test_n  / test_counts.sum() * 100, 1) if test_counts.sum() else 0\n",
    "            val_pct   = round(val_n   / val_counts.sum() * 100, 1) if val_counts.sum() else 0\n",
    "\n",
    "            records.append({\n",
    "                \"predictor\": pred,\n",
    "                \"category\": cat,\n",
    "                \"train\": train_n,\n",
    "                \"test\": test_n,\n",
    "                \"val\": val_n,\n",
    "                \"train_percent\": train_pct,\n",
    "                \"test_percent\": test_pct,\n",
    "                \"val_percent\": val_pct\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3e707d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assign_stage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_df \u001b[38;5;241m=\u001b[39m \u001b[43massign_stage\u001b[49m(test_df)\n\u001b[1;32m      2\u001b[0m train_df \u001b[38;5;241m=\u001b[39m assign_stage(train_df)\n\u001b[1;32m      3\u001b[0m val_df\u001b[38;5;241m=\u001b[39m assign_stage(val_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'assign_stage' is not defined"
     ]
    }
   ],
   "source": [
    "test_df = assign_stage(test_df)\n",
    "train_df = assign_stage(train_df)\n",
    "val_df= assign_stage(val_df)\n",
    "\n",
    "test_df = assign_grade_by_patient(test_df)\n",
    "train_df = assign_grade_by_patient(train_df)\n",
    "val_df = assign_grade_by_patient(val_df)\n",
    "\n",
    "train_df= assign_extent(train_df)\n",
    "test_df= assign_extent(test_df)\n",
    "val_df= assign_extent(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"val_df.csv\", index=False)\n",
    "train_df.to_csv(\"train_df.csv\", index=False)\n",
    "test_df.to_csv(\"test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=_get_summary_data(train_df, test_df, val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_latex(\"summary.tex\", index=False, float_format=\"%.1f\", escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Revision/Dataset_Leuven.xlsx\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277106e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure both columns are datetime\n",
    "df[\"ExaminationDate\"] = pd.to_datetime(df[\"ExaminationDate\"])\n",
    "df[\"ExaminationDate_rev\"] = pd.to_datetime(df[\"ExaminationDate_rev\"])\n",
    "\n",
    "# Calculate month difference (rounded down)\n",
    "df[\"months_between\"] = (\n",
    "    (df[\"ExaminationDate_rev\"].dt.year - df[\"ExaminationDate\"].dt.year) * 12 +\n",
    "    (df[\"ExaminationDate_rev\"].dt.month - df[\"ExaminationDate\"].dt.month)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9825b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tooth</th>\n",
       "      <th>PD</th>\n",
       "      <th>Mobility</th>\n",
       "      <th>BOP</th>\n",
       "      <th>RootNumber</th>\n",
       "      <th>Toothtype</th>\n",
       "      <th>Restoration</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExaminationDate</th>\n",
       "      <th>...</th>\n",
       "      <th>BOP_rev</th>\n",
       "      <th>ExaminationDate_rev</th>\n",
       "      <th>Furcation</th>\n",
       "      <th>Furcation_rev</th>\n",
       "      <th>BodyMassIndex</th>\n",
       "      <th>CigaretteNumber</th>\n",
       "      <th>Stresslvl</th>\n",
       "      <th>Sickdays_Year</th>\n",
       "      <th>Plaque (%)</th>\n",
       "      <th>months_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14464.000000</td>\n",
       "      <td>14374.000000</td>\n",
       "      <td>14380.000000</td>\n",
       "      <td>14380.000000</td>\n",
       "      <td>13726.000000</td>\n",
       "      <td>13726.000000</td>\n",
       "      <td>13459.000000</td>\n",
       "      <td>1.438000e+04</td>\n",
       "      <td>14380.000000</td>\n",
       "      <td>14380</td>\n",
       "      <td>...</td>\n",
       "      <td>13993.000000</td>\n",
       "      <td>13993</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>6888.000000</td>\n",
       "      <td>2490.000000</td>\n",
       "      <td>14050.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.169939</td>\n",
       "      <td>3.669125</td>\n",
       "      <td>1.695688</td>\n",
       "      <td>1.676843</td>\n",
       "      <td>1.350794</td>\n",
       "      <td>1.837899</td>\n",
       "      <td>0.719816</td>\n",
       "      <td>7.255321e+07</td>\n",
       "      <td>49.011822</td>\n",
       "      <td>2022-12-22 09:24:41.057023744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229758</td>\n",
       "      <td>2023-08-09 12:15:04.566569216</td>\n",
       "      <td>1.181347</td>\n",
       "      <td>1.272237</td>\n",
       "      <td>26.561463</td>\n",
       "      <td>10.867470</td>\n",
       "      <td>4.544270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.645913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.020561e+07</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2020-12-16 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-06-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.377748e+07</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2022-02-22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2022-10-26 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.770000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.160635e+07</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2023-01-18 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-10-04 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.091320e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2023-11-28 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2024-06-18 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.370000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.985197e+07</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2024-06-03 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2024-10-14 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.436160</td>\n",
       "      <td>1.731837</td>\n",
       "      <td>0.562916</td>\n",
       "      <td>0.467698</td>\n",
       "      <td>0.477236</td>\n",
       "      <td>0.838349</td>\n",
       "      <td>0.515651</td>\n",
       "      <td>9.608890e+06</td>\n",
       "      <td>13.486381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665458</td>\n",
       "      <td>0.513346</td>\n",
       "      <td>4.762956</td>\n",
       "      <td>4.981858</td>\n",
       "      <td>1.188209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.295736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tooth            PD      Mobility           BOP    RootNumber  \\\n",
       "count  14464.000000  14374.000000  14380.000000  14380.000000  13726.000000   \n",
       "mean      29.169939      3.669125      1.695688      1.676843      1.350794   \n",
       "min       11.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%       21.000000      2.000000      1.000000      1.000000      1.000000   \n",
       "50%       31.000000      3.000000      2.000000      2.000000      1.000000   \n",
       "75%       41.000000      5.000000      2.000000      2.000000      2.000000   \n",
       "max       48.000000     15.000000      2.000000      2.000000      2.000000   \n",
       "std       11.436160      1.731837      0.562916      0.467698      0.477236   \n",
       "\n",
       "          Toothtype   Restoration            ID           Age  \\\n",
       "count  13726.000000  13459.000000  1.438000e+04  14380.000000   \n",
       "mean       1.837899      0.719816  7.255321e+07     49.011822   \n",
       "min        1.000000      0.000000  6.020561e+07     24.000000   \n",
       "25%        1.000000      0.000000  6.377748e+07     38.000000   \n",
       "50%        2.000000      1.000000  7.160635e+07     51.000000   \n",
       "75%        3.000000      1.000000  8.091320e+07     60.000000   \n",
       "max        3.000000      2.000000  8.985197e+07     76.000000   \n",
       "std        0.838349      0.515651  9.608890e+06     13.486381   \n",
       "\n",
       "                     ExaminationDate  ...       BOP_rev  \\\n",
       "count                          14380  ...  13993.000000   \n",
       "mean   2022-12-22 09:24:41.057023744  ...      1.229758   \n",
       "min              2020-12-16 00:00:00  ...      1.000000   \n",
       "25%              2022-02-22 00:00:00  ...      1.000000   \n",
       "50%              2023-01-18 00:00:00  ...      1.000000   \n",
       "75%              2023-11-28 00:00:00  ...      1.000000   \n",
       "max              2024-06-03 00:00:00  ...      2.000000   \n",
       "std                              NaN  ...      0.420692   \n",
       "\n",
       "                 ExaminationDate_rev   Furcation Furcation_rev  BodyMassIndex  \\\n",
       "count                          13993  579.000000    371.000000    6888.000000   \n",
       "mean   2023-08-09 12:15:04.566569216    1.181347      1.272237      26.561463   \n",
       "min              2021-06-01 00:00:00    0.000000      0.000000      19.050000   \n",
       "25%              2022-10-26 00:00:00    1.000000      1.000000      22.770000   \n",
       "50%              2023-10-04 00:00:00    1.000000      1.000000      25.900000   \n",
       "75%              2024-06-18 00:00:00    2.000000      2.000000      28.370000   \n",
       "max              2024-10-14 00:00:00    3.000000      3.000000      40.000000   \n",
       "std                              NaN    0.665458      0.513346       4.762956   \n",
       "\n",
       "       CigaretteNumber     Stresslvl  Sickdays_Year  Plaque (%)  \\\n",
       "count      2490.000000  14050.000000            0.0         0.0   \n",
       "mean         10.867470      4.544270            NaN         NaN   \n",
       "min           2.000000      2.000000            NaN         NaN   \n",
       "25%           6.000000      4.000000            NaN         NaN   \n",
       "50%          10.000000      5.000000            NaN         NaN   \n",
       "75%          15.000000      5.000000            NaN         NaN   \n",
       "max          20.000000      8.000000            NaN         NaN   \n",
       "std           4.981858      1.188209            NaN         NaN   \n",
       "\n",
       "       months_between  \n",
       "count    13909.000000  \n",
       "mean         7.645913  \n",
       "min          3.000000  \n",
       "25%          5.000000  \n",
       "50%          7.000000  \n",
       "75%          9.000000  \n",
       "max         32.000000  \n",
       "std          4.295736  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pamod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
